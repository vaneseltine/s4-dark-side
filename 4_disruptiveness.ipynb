{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3bcf866",
   "metadata": {},
   "source": [
    "https://novelpy.readthedocs.io/en/latest/indicators.html#wu-et-al-2019-bornmann-et-al-2019-bu-et-al-2019\n",
    "\n",
    "---\n",
    "\n",
    "\"To increase the validity of the indicators included in this study, we considered only papers with at least 10 cited references and at least 10 citations. \"\n",
    "\n",
    "Bornmann, L., Devarakonda, S., Tekles, A., & Chacko, G. (2020). Are disruption index indicators convergently valid? The comparison of several indicator variants with assessments by peers. Quantitative Science Studies, 1(3), 1242–1259. https://doi.org/10.1162/qss_a_00068\n",
    "\n",
    "---\n",
    "\n",
    "Bu, Y., Waltman, L., & Huang, Y. (2021). A multidimensional framework for characterizing the citation impact of scientific publications. Quantitative Science Studies, 2(1), 155–183. https://doi.org/10.1162/qss_a_00109\n",
    "\n",
    "di_nok_1 is highly correlated (>.8) with di_nok_5, di_5\n",
    "\n",
    "---\n",
    "\n",
    "Wu & Yan (2019) and Wu & Wu (2019) argue against including citations to the focal work's references (\"prelude citations\") and conclude that \"four indicators (SC, SC-DC, SC/(SC+DC), and (SC-DC)/(SC+DC)) are logically and empirically reasonable.\" We use here (SC-DC)/(SC+DC).\n",
    "\n",
    "Wu, S., & Wu, Q. (2019). A confusing definition of disruption. SocArXiv. https://doi.org/10.31235/osf.io/d3wpk\n",
    "\n",
    "Wu, Q., & Yan, Z. (2019). Solo citations, duet citations, and prelude citations: New measures of the disruption of academic papers (arXiv:1905.03461). arXiv. https://doi.org/10.48550/arXiv.1905.03461\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c71ed9c",
   "metadata": {},
   "source": [
    "# from https://github.com/Kwirtz/novelpy/blob/main/novelpy/indicators/WuBuBornmann.py\n",
    "\"\"\"\n",
    "    # papers that cite the focal paper that also cite reference from the focal paper\n",
    "    J = set(citing_focal_paper.keys()).intersection(citing_ref_from_focal_paper.keys())\n",
    "\n",
    "    # papers that cite the focal paper but do not cite reference from the focal paper\n",
    "    I = set(citing_focal_paper.keys()) - J\n",
    "\n",
    "    # papers that do not cite the focal paper but cite reference from the focal paper\n",
    "    K = set(citing_ref_from_focal_paper.keys()) - J\n",
    "\n",
    "    # number of reference cited by a paper that cite the focal paper that are cited by the focal paper\n",
    "    Jxc = [len(set(focal_paper_refs).intersection(cited_ref)) for cited_ref in citing_focal_paper.values()]\n",
    "\n",
    "    # keep papers that cite the focal paper that share at least 5 references with the focal paper\n",
    "    J5 = [len_match_ref for len_match_ref in Jxc if len_match_ref > 4]\n",
    "\n",
    "    # papers that cite the focal paper that do not cite papers that cite the focal paper\n",
    "    Breadth = [pmid for pmid in citing_focal_paper\n",
    "               if not any([ref in citing_focal_paper.keys() for ref in citing_focal_paper[pmid]])]\n",
    "\n",
    "    # papers that cite the focal paper that cite at least one other paper that cite the focal paper\n",
    "    Depth = [pmid for pmid in citing_focal_paper\n",
    "               if any([ref in citing_focal_paper.keys() for ref in citing_focal_paper[pmid]])]\n",
    "\n",
    "    len_I = len(I) if I else 0\n",
    "    len_J = len(J) if J else 0\n",
    "    len_J5 = len(J5) if J5 else 0\n",
    "    len_K = len(K) if K else 0\n",
    "    sum_Jxc = sum(Jxc) if Jxc else 0\n",
    "    len_B = len(Breadth) if Breadth else 0\n",
    "    len_D = len(Depth) if Depth else 0\n",
    "\n",
    "    disruptiveness_indicators = {\n",
    "        'disruptiveness' : {\n",
    "            'DI1': (len_I-len_J)/(len_I+len_J+len_K) if any([len_I,len_J,len_K !=0]) else 0,\n",
    "            'DI5': (len_I-len_J5)/(len_I+len_J5+len_K)if any([len_I,len_J5,len_K !=0]) else 0,\n",
    "            'DI5nok': (len_I-len_J5)/(len_I+len_J5) if any([len_I,len_J5 !=0]) else 0,\n",
    "            'DI1nok': (len_I-len_J)/(len_I+len_J) if any([len_I,len_J !=0]) else 0,\n",
    "            'DeIn': sum_Jxc/(len_I+len_J) if any([len_I,len_J !=0]) else 0,\n",
    "            'Breadth' : len_B/(len_I+len_J) if any([len_I,len_J !=0]) else 0,\n",
    "            'Depth' : len_D/(len_I+len_J) if any([len_I,len_J !=0]) else 0\n",
    "            }\n",
    "        }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32531c0",
   "metadata": {},
   "source": [
    "## Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e900ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.8/site-packages (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.8/site-packages (from pyarrow) (1.19.5)\n",
      "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
      "distutils: /opt/conda/include/python3.8/UNKNOWN\n",
      "sysconfig: /opt/conda/include/python3.8\u001b[0m\n",
      "\u001b[33mWARNING: Additional context:\n",
      "user = False\n",
      "home = None\n",
      "root = None\n",
      "prefix = None\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "787d5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_DIR = Path('./data')\n",
    "\n",
    "# input\n",
    "RAW_COLLATED_PATH = DATA_DIR / 'raw_collated.json'\n",
    "# output\n",
    "DISR_DF_PATH = DATA_DIR / 'disruption_df.feather'\n",
    "\n",
    "PER_PAGE = 200 # API max\n",
    "# not using this -- but should we limit cites to type:journal-article ? \n",
    "# SHARED_FILTERS = \"type:journal-article,publication_year:>2010,publication_year:<2018\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6154842",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CORE_DF_PATH = DATA_DIR / 'core_df.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58575e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# core_df = pd.read_feather(CORE_DF_PATH)\n",
    "# core_df.sort_values('cited_by_count', ascending=False).head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "49dd69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PER_PAGE = 200\n",
    "\n",
    "def retrieve_all_openalex_records(base_url, delay=1, max_pages=1000):\n",
    "    \"\"\"Don't send per_page and page, we'll handle pagination\"\"\"\n",
    "    assert \"&page=\" not in base_url\n",
    "    \n",
    "    half_delay = delay/2\n",
    "    \n",
    "    records = []\n",
    "    for page in range(1, (max_pages + 1)):\n",
    "        pagination = f\"per_page={PER_PAGE}&page={page}\"\n",
    "        url = \"&\".join((base_url, pagination))\n",
    "        time.sleep(half_delay) \n",
    "        got = requests.get(url)\n",
    "        \n",
    "        try:\n",
    "            j = got.json()\n",
    "        except json.JSONDecodeError as err:\n",
    "            print('oop made it angry')\n",
    "            print(url)\n",
    "            print('and we got')\n",
    "            print(got)\n",
    "            raise err\n",
    "            \n",
    "        try:\n",
    "            print(j['meta'])\n",
    "        except KeyError as err:\n",
    "            print('oop made it angry')\n",
    "            print(url)\n",
    "            print('and we got')\n",
    "            print(got)\n",
    "            raise err\n",
    "\n",
    "        if page == 1:\n",
    "            print(url)\n",
    "\n",
    "        records += j['results']\n",
    "\n",
    "        count = j['meta']['count']\n",
    "        page = j['meta']['page']\n",
    "        per_page = j['meta']['per_page']\n",
    "        time.sleep(half_delay) \n",
    "        if per_page * page >= count:\n",
    "            break\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1d28baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "# N_YEARS_CITATIONS = 5\n",
    "# f\",publication_year:<{too_late}\" ## so.... turns out cited url only returns 30. just... 30.\n",
    "print([i for i in range(1, 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "with RAW_COLLATED_PATH.open('r', encoding='UTF-8') as infile:\n",
    "    raw_records = json.load(infile)\n",
    "# so all I need is the name of the work and its refs\n",
    "focal_works = {\n",
    "    r['id'].replace('https://openalex.org/', ''): set(x.replace('https://openalex.org/', '') for x in r['referenced_works'])\n",
    "    for r in raw_records\n",
    "}\n",
    "all_refs_of_focal_works = set.union(*focal_works.values())\n",
    "len(all_refs_of_focal_works)\n",
    "print(f'{len(focal_works):,} works and {len(all_refs_of_focal_works):,} references')\n",
    "# free up some memory!\n",
    "del raw_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "24fd76ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113937\n"
     ]
    }
   ],
   "source": [
    "# this can be cached, as the raw records won't be needed again\n",
    "known_refs = {fw: list(refs) for fw, refs in focal_works.items()}\n",
    "print(len(known_refs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0f26a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88827"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many have at least 10 references?\n",
    "len([k for k, v in focal_works.items() if len(v) >= 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ce25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = \"\"\"\n",
    "\n",
    "cites\n",
    "Value: the OpenAlex ID for a given work\n",
    "Returns: works that cite the given work. You can think of this as incoming citations. \n",
    "Get works that cite https://openalex.org/W2741809807: https://api.openalex.org/works?filter%3Dcites%3AW2741809807\n",
    "\n",
    "cited_by\n",
    "Value: the OpenAlex ID for a given work\n",
    "Returns: works found in the given work's referenced_work section. You can think of this as outgoing citations. \n",
    "Get works cited by https://openalex.org/W2766808518: https://api.openalex.org/works?filter%3Dcited_by%3AW2766808518\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08eece45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/disruption_df.feather')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DISR_DF_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cd96388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # original creation -- rather important not to accidentally overwrite this!\n",
    "# disr_df = pd.DataFrame(index=focal_works.keys(), columns='di_nok_1 focal_refs len_I len_J fetched'.split())\n",
    "# disr_df.index.rename('id', inplace=True)\n",
    "# disr_df['fetched'].fillna(value=False, inplace=True)\n",
    "# # have to bounce the index to a column to feather out\n",
    "# disr_df.reset_index().to_feather(DISR_DF_PATH)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf8c483e",
   "metadata": {},
   "source": [
    "# known_refs_json = DATA_DIR / 'known_refs.json'\n",
    "tracker = DATA_DIR / 'known_refs_tracker.txt'\n",
    "# tracker.write_text('0')\n",
    "# auto restart\n",
    "start = int(tracker.read_text().strip())\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by chunking our job 50 ids at a time,\n",
    "# we only need 2,279 (about 38 minutes at 1 second per) queries...\n",
    "# it actually takes about 3x that because the average 50-id request returns 400-600 refs\n",
    "# but still! 17x faster at 3x... call it around 2h raw API time\n",
    "# rather than the full 113,937 (31h 39m) or even the reduced 88k (24h 27m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5455d96d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113937 items of 113937 handled\n"
     ]
    }
   ],
   "source": [
    "disr_df = pd.read_feather(DISR_DF_PATH).set_index('id')\n",
    "\n",
    "# by keeping this sorted, we can keep track of what we have or haven't visited\n",
    "ids = sorted(list(pd.read_feather(DISR_DF_PATH)['id']))\n",
    "# print(ids[:10])\n",
    "\n",
    "# I can do 50 at a time using filter on ID and intersection e.g.\n",
    "# https://api.openalex.org/works?mailto=matvan@umich.edu&filter=cites:W2737572559|W2737572559|W3041843825&per_page=200&page=1\n",
    "batch_size = 50 \n",
    "delay = 1\n",
    "\n",
    "for i in range(0, len(ids), batch_size):\n",
    "    clear_output(wait=True)\n",
    "    print(len(disr_df[disr_df.fetched == True]), 'items of', len(disr_df), 'handled')\n",
    "    if len(disr_df[disr_df.fetched == True]) == len(disr_df):\n",
    "        break\n",
    "    print('i =', i)\n",
    "    raw_id_batch = ids[i:i+batch_size]\n",
    "    id_batch = [x for x in raw_id_batch if not disr_df.loc[x].fetched]\n",
    "    if not id_batch:\n",
    "        continue\n",
    "    print('batch =', id_batch)\n",
    "    mini_refs_network = {x: known_refs[x] for x in id_batch}\n",
    "    # TODO next time -- type=journal-article\n",
    "    cited_url = f\"https://api.openalex.org/works?mailto=matvan@umich.edu&filter=cites:\" + '|'.join(id_batch)\n",
    "    records_batch = retrieve_all_openalex_records(cited_url, delay=delay, max_pages=50)\n",
    "    print('Adding', len(records_batch))\n",
    "    \n",
    "    for rec in records_batch:\n",
    "        r_id = rec['id'].replace('https://openalex.org/', '')\n",
    "        mini_refs_network[r_id] = [x.replace('https://openalex.org/', '') for x in rec['referenced_works']]\n",
    "\n",
    "    # next we'll invert the dictionary\n",
    "    # so we go from list of papers: list of refs to list of refs: list of papers\n",
    "    print('mini_refs_network', len(mini_refs_network))\n",
    "    print('citee_to_citer', len(citee_to_citer))\n",
    "\n",
    "    citee_to_citer = defaultdict(list)\n",
    "    for paper, refs in mini_refs_network.items():\n",
    "    #     print(paper)\n",
    "        for ref in refs:\n",
    "            citee_to_citer[ref].append(paper)\n",
    "\n",
    "    for j, focal_id in enumerate(id_batch):\n",
    "\n",
    "        print(focal_id, end='... ')\n",
    "\n",
    "        focal_refs = set(mini_refs_network[focal_id])\n",
    "        citing_works = {k: set(mini_refs_network[k]) for k in citee_to_citer[focal_id]}\n",
    "\n",
    "        # papers that cite the focal paper that also cite reference from the focal paper\n",
    "        # novelpy J = set(citing_focal_paper.keys()).intersection(citing_ref_from_focal_paper.keys())\n",
    "        J = set(cw for cw, cw_refs in citing_works.items() if cw_refs & focal_refs)\n",
    "\n",
    "        J_n_dict = {cw: len(cw_refs & focal_refs) for cw, cw_refs in citing_works.items() if (cw_refs & focal_refs)}\n",
    "\n",
    "        # papers that cite the focal paper but do not cite reference from the focal paper\n",
    "        # novelpy I = set(citing_focal_paper.keys()) - J\n",
    "\n",
    "        I = set(citing_works.keys()) - J\n",
    "        len_I = len(I)\n",
    "        len_J = len(J)\n",
    "\n",
    "        #         print('J', len(J), J)\n",
    "        #         print('J_n_dict', len(J_n_dict), J_n_dict)\n",
    "        #         print('I', len(I), I)\n",
    "\n",
    "        # 0 case (i.e. literally no citations to the focal work) handled earlier\n",
    "        # Rather than set to 0, better I think to assert that works with no citations \n",
    "        # cannot have their developmental/disruptive influence calculated.\n",
    "\n",
    "        try:\n",
    "            di_nok_1 = (len_I-len_J)/(len_I+len_J) \n",
    "        except ZeroDivisionError:\n",
    "            # oy, got no citations here\n",
    "            di_nok_1 = None\n",
    "\n",
    "\n",
    "        row = [di_nok_1, len(focal_refs), len_I, len_J, True]\n",
    "        print(row)\n",
    "        disr_df.loc[focal_id] = row\n",
    "\n",
    "\n",
    "    print('Writing df to', DISR_DF_PATH)\n",
    "    disr_df.reset_index().to_feather(DISR_DF_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e6d0825d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>di_nok_1</th>\n",
       "      <th>focal_refs</th>\n",
       "      <th>len_I</th>\n",
       "      <th>len_J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97338.000000</td>\n",
       "      <td>113937.000000</td>\n",
       "      <td>113782.000000</td>\n",
       "      <td>113782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.209524</td>\n",
       "      <td>31.629585</td>\n",
       "      <td>7.031692</td>\n",
       "      <td>14.223436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.621898</td>\n",
       "      <td>31.869399</td>\n",
       "      <td>39.775831</td>\n",
       "      <td>38.743563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.692308</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1355.000000</td>\n",
       "      <td>8002.000000</td>\n",
       "      <td>3834.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           di_nok_1     focal_refs          len_I          len_J\n",
       "count  97338.000000  113937.000000  113782.000000  113782.000000\n",
       "mean      -0.209524      31.629585       7.031692      14.223436\n",
       "std        0.621898      31.869399      39.775831      38.743563\n",
       "min       -1.000000       0.000000       0.000000       0.000000\n",
       "25%       -0.692308      12.000000       1.000000       1.000000\n",
       "50%       -0.333333      27.000000       3.000000       5.000000\n",
       "75%        0.142857      43.000000       7.000000      15.000000\n",
       "max        1.000000    1355.000000    8002.000000    3834.000000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disr_df.describe()"
   ]
  }
 ],
 "metadata": {
  "author": "me",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
